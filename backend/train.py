# -*- coding: utf-8 -*-
"""train

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o62bb5wudkEt6gwGZCwI-DoSavr1Fr-u
"""

import pandas as pd
import os
import random
from faker import Faker

# Initialize Faker for generating realistic-sounding names
fake = Faker('en_IN') # Using Indian locale for relevant names

# --- Configuration ---
NUM_TRAINS_TO_GENERATE = 50
OUTPUT_DIR = 'data'

def generate_synthetic_data():
    """
    Generates and saves a comprehensive, synthetic railway dataset including stations,
    tracks, and a large number of train service requests.
    """
    print("--- Starting Advanced Synthetic Data Generation ---")

    # Create the output directory if it doesn't exist
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
        print(f"Created directory: {OUTPUT_DIR}")

    # --- 1. Generate Stations Data ---
    # We will define a major, realistic corridor for coherence.
    stations_list = [
        {'station_id': 'NDLS', 'station_name': 'New Delhi', 'city': 'Delhi', 'zone': 'NR', 'platforms': 16},
        {'station_id': 'MTJ', 'station_name': 'Mathura Jn', 'city': 'Mathura', 'zone': 'NCR', 'platforms': 9},
        {'station_id': 'KOTA', 'station_name': 'Kota Jn', 'city': 'Kota', 'zone': 'WCR', 'platforms': 6},
        {'station_id': 'RTM', 'station_name': 'Ratlam Jn', 'city': 'Ratlam', 'zone': 'WR', 'platforms': 7},
        {'station_id': 'BRC', 'station_name': 'Vadodara Jn', 'city': 'Vadodara', 'zone': 'WR', 'platforms': 7},
        {'station_id': 'ST', 'station_name': 'Surat', 'city': 'Surat', 'zone': 'WR', 'platforms': 4},
        {'station_id': 'BVI', 'station_name': 'Borivali', 'city': 'Mumbai', 'zone': 'WR', 'platforms': 8},
        {'station_id': 'MMCT', 'station_name': 'Mumbai Central', 'city': 'Mumbai', 'zone': 'WR', 'platforms': 5}
    ]
    stations_df = pd.DataFrame(stations_list)
    stations_df.to_csv(os.path.join(OUTPUT_DIR, 'stations.csv'), index=False)
    print(f"-> Successfully generated {len(stations_df)} stations in '{OUTPUT_DIR}/stations.csv'")

    # --- 2. Generate Tracks Data ---
    # Create tracks connecting the stations in sequence
    tracks_list = []
    for i in range(len(stations_list) - 1):
        start_station = stations_list[i]
        end_station = stations_list[i+1]

        # Introduce a single-line bottleneck for realism
        is_single = True if start_station['station_id'] == 'KOTA' else False

        tracks_list.append({
            'track_id': f"{start_station['station_id']}-{end_station['station_id']}",
            'start_station': start_station['station_id'],
            'end_station': end_station['station_id'],
            'length_km': random.randint(100, 300),
            'max_speed_kmh': random.choice([100, 110, 120, 130]),
            'is_single_line': is_single,
            'track_count': 1 if is_single else 2
        })
    tracks_df = pd.DataFrame(tracks_list)
    tracks_df.to_csv(os.path.join(OUTPUT_DIR, 'tracks.csv'), index=False)
    print(f"-> Successfully generated {len(tracks_df)} track sections in '{OUTPUT_DIR}/tracks.csv'")

    # --- 3. Generate Train Service Requests ---
    train_requests_list = []
    train_types = {
        'Rajdhani/Shatabdi': 1,
        'Superfast Express': 2,
        'Mail/Express': 3,
        'Passenger/Local': 4,
        'Goods Freight': 5
    }
    station_ids = stations_df['station_id'].tolist()

    for i in range(NUM_TRAINS_TO_GENERATE):
        train_no = str(random.randint(10000, 29999))
        train_type = random.choices(list(train_types.keys()), weights=[10, 30, 30, 10, 20], k=1)[0]
        priority = train_types[train_type]

        # Ensure start and end are not the same
        start, end = random.sample(station_ids, 2)

        # Generate a realistic name
        if 'Freight' in train_type:
            train_name = f"Container Goods {random.randint(100, 999)}"
            train_no = f"{random.randint(4000, 9999)}-F"
        else:
            train_name = f"{fake.city_name()} {train_type.replace('Superfast ', '')}"

        train_requests_list.append({
            'train_no': train_no,
            'train_name': train_name,
            'train_type': train_type,
            'start_station': start,
            'end_station': end,
            'priority': priority
        })

    train_requests_df = pd.DataFrame(train_requests_list)
    train_requests_df.to_csv(os.path.join(OUTPUT_DIR, 'schedule_requests.csv'), index=False)
    print(f"-> Successfully generated {len(train_requests_df)} train requests in '{OUTPUT_DIR}/schedule_requests.csv'")

    print("\n--- Synthetic Data Generation Complete! ---")

if __name__ == '__main__':
    generate_synthetic_data()

pip install faker

import pandas as pd
import os

print("Contents of data/stations.csv:")
stations_df = pd.read_csv('data/stations.csv')
display(stations_df)

print("\nContents of data/tracks.csv:")
tracks_df = pd.read_csv('data/tracks.csv')
display(tracks_df)

print("\nContents of data/schedule_requests.csv:")
schedule_requests_df = pd.read_csv('data/schedule_requests.csv')
display(schedule_requests_df)

print("\nContents of data/generated_timetable.csv:")
timetable_df = pd.read_csv('data/generated_timetable.csv')
display(timetable_df)

import pandas as pd
import networkx as nx
import os

def create_schedule():
    """Reads network data and train requests to generate a full timetable."""
    print("Running Strategic Scheduler to generate master timetable...")

    stations_df = pd.read_csv('data/stations.csv')
    tracks_df = pd.read_csv('data/tracks.csv')
    requests_df = pd.read_csv('data/schedule_requests.csv')

    # Create a graph representation of the railway network
    G = nx.Graph()
    for _, station in stations_df.iterrows():
        G.add_node(station['station_id'], name=station['station_name'])
    for _, track in tracks_df.iterrows():
        # Calculate travel time in minutes as weight
        travel_time = (track['length_km'] / (track['max_speed_kmh'] * 0.75)) * 60 # Assume avg speed is 75% of max
        G.add_edge(track['start_station'], track['end_station'], weight=travel_time, track_id=track['track_id'])

    timetable = []
    current_time = 0 # Simple time staggering, starts at minute 0

    # Sort requests by priority to schedule important trains first
    requests_df = requests_df.sort_values(by='priority')

    for _, train in requests_df.iterrows():
        path = nx.shortest_path(G, source=train['start_station'], target=train['end_station'], weight='weight')

        departure_time = current_time
        arrival_time = departure_time

        for i in range(len(path) - 1):
            start_node = path[i]
            end_node = path[i+1]
            edge_data = G.get_edge_data(start_node, end_node)
            travel_time = edge_data['weight']

            timetable.append({
                'train_no': train['train_no'],
                'train_name': train['train_name'],
                'sequence': i + 1,
                'station_from': start_node,
                'station_to': end_node,
                'scheduled_departure': arrival_time,
                'scheduled_arrival': arrival_time + travel_time,
                'track_id': edge_data['track_id']
            })
            arrival_time += travel_time + 5 # Add 5 min halt time at each station

        # Stagger the next train's departure
        current_time += 15

    timetable_df = pd.DataFrame(timetable)
    timetable_df.to_csv('data/generated_timetable.csv', index=False)
    print("  - Master timetable created: data/generated_timetable.csv")

from stable_baselines3 import PPO
import pandas as pd
import os
# The DigitalTwinEnv class is defined in the main.py cell for execution context.

def train_agent():
    """Initializes the environment and trains the PPO agent."""
    print("Loading data for the Digital Twin Environment...")
    timetable_df = pd.read_csv('data/generated_timetable.csv')
    tracks_df = pd.read_csv('data/tracks.csv')

    # Create the Digital Twin environment
    # DigitalTwinEnv is defined in the cell containing the main() function
    env = DigitalTwinEnv(timetable_df, tracks_df)

    # Instantiate the PPO model
    model = PPO("MlpPolicy", env, verbose=0)

    # Train the agent
    print("Training the RL agent... (This may take a few minutes)")
    # Note: 10,000 timesteps is for a quick demonstration. A real model would need millions.
    model.learn(total_timesteps=10000)
    print("  - Training complete.")

    # Save the trained model
    if not os.path.exists('models'):
        os.makedirs('models')
    model.save("models/railopt_ai_agent")
    print("  - Trained model saved to models/railopt_ai_agent.zip")

    return model, env

def run_simulation_with_agent(model, env):
    """Runs a single simulation episode using the trained agent and renders it."""
    print("\n--- Running simulation with the TRAINED agent ---")
    obs, info = env.reset()
    env.render()

    for _ in range(200): # Max steps per episode
        action, _states = model.predict(obs, deterministic=True)
        obs, reward, terminated, truncated, info = env.step(action)
        env.render()
        if terminated:
            print("--- All trains arrived! ---")
            break

pip install stable_baselines3

import gymnasium as gym
from gymnasium import spaces
import numpy as np
import pandas as pd
import random

# 3. Digital Twin Environment (digital_twin_env.py) - Class Definition
class DigitalTwinEnv(gym.Env):
    """A Gymnasium environment for the railway Digital Twin."""
    def __init__(self, timetable_df, tracks_df):
        super(DigitalTwinEnv, self).__init__()

        self.timetable = timetable_df
        self.tracks = tracks_df.set_index('track_id').to_dict('index')
        self.train_ids = self.timetable['train_no'].unique()
        self.num_trains = len(self.train_ids)
        self.num_tracks = len(self.tracks)

        # Action: For each train, decide to HOLD (0) or PROCEED (1)
        self.action_space = spaces.MultiBinary(self.num_trains)

        # Observation: [train_pos, train_delay] for each train
        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(self.num_trains * 2,), dtype=np.float32)

        self.reset()

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self.time = 0
        self.train_states = {}

        for train_id in self.train_ids:
            # Introduce a random initial delay for some trains to create disruptions
            initial_delay = random.randint(0, 15) if random.random() < 0.3 else 0
            self.train_states[train_id] = {
                'position_km': 0,
                'current_track_idx': 0,
                'delay_mins': initial_delay,
                'status': 'RUNNING',
                'route': self.timetable[self.timetable['train_no'] == train_id].to_dict('records')
            }
        return self._get_obs(), self._get_info()

    def step(self, action):
        reward = 0

        # Simple conflict detection: check single-line track usage
        occupied_single_tracks = set()

        for i, train_id in enumerate(self.train_ids):
            state = self.train_states[train_id]
            if state['status'] != 'RUNNING':
                continue

            # If action is HOLD, the train doesn't move
            if action[i] == 0:
                state['delay_mins'] += 1
                continue

            route_step = state['route'][state['current_track_idx']]
            track_id = route_step['track_id']
            track_info = self.tracks[track_id]

            # Conflict check for single line
            if track_info['is_single_line']:
                if track_id in occupied_single_tracks:
                    state['delay_mins'] += 1 # Cannot proceed, another train is on the single line
                    reward -= 10 # Penalty for conflict
                    continue
                else:
                    occupied_single_tracks.add(track_id)

            # Move the train
            avg_speed = track_info['max_speed_kmh'] * 0.75
            dist_per_min = avg_speed / 60
            state['position_km'] += dist_per_min

            # Check if arrived at next station
            if state['position_km'] >= track_info['length_km']:
                state['current_track_idx'] += 1
                state['position_km'] = 0
                if state['current_track_idx'] >= len(state['route']):
                    state['status'] = 'ARRIVED'
                    reward += 100 # Reward for finishing
                else:
                    # Check for delay at station
                    current_arrival_time = self.time
                    scheduled_arrival = state['route'][state['current_track_idx']-1]['scheduled_arrival']
                    state['delay_mins'] = max(0, current_arrival_time - scheduled_arrival)
                    reward -= state['delay_mins'] # Penalty proportional to delay

        self.time += 1 # Each step is one minute

        terminated = all(s['status'] == 'ARRIVED' for s in self.train_states.values())
        return self._get_obs(), reward, terminated, False, self._get_info()

    def _get_obs(self):
        obs = np.zeros(self.observation_space.shape, dtype=np.float32)
        for i, train_id in enumerate(self.train_ids):
            state = self.train_states[train_id]
            obs[i*2] = state['position_km']
            obs[i*2 + 1] = state['delay_mins']
        return obs

    def _get_info(self):
        return {id: s['delay_mins'] for id, s in self.train_states.items()}

    def render(self):
        print(f"\n--- Time: {self.time} minutes ---")
        for train_id, state in self.train_states.items():
            if state['status'] == 'RUNNING':
                route_step = state['route'][state['current_track_idx']]
                track_id = route_step['track_id']
                track_len = self.tracks[track_id]['length_km']
                progress = int((state['position_km'] / track_len) * 20)
                track_viz = f"[{'='*progress}>{'-'*(20-progress)}]"
                print(f"  Train {train_id}: {route_step['station_from']} {track_viz} {route_step['station_to']} | Delay: {int(state['delay_mins'])} min")
            else:
                print(f"  Train {train_id}: {state['status']}")


def main():
    """Main function to run the entire project pipeline."""

    print("===== RailOpt AI Project Pipeline Starting =====\n")

    # Step 1: Generate synthetic data
    print("--- STEP 1: GENERATING SYNTHETIC DATA ---")
    generate_data()
    print("\nData generation complete.\n" + "="*40 + "\n")

    # Step 2: Create a schedule from the data
    print("--- STEP 2: RUNNING STRATEGIC SCHEDULER ---")
    create_schedule()
    print("\nTimetable generation complete.\n" + "="*40 + "\n")

    # Step 3: Train the RL agent and run a final simulation
    print("--- STEP 3 & 4: TRAINING RL AGENT & DEMONSTRATION ---")
    model, env = train_agent()
    run_simulation_with_agent(model, env)
    print("\nDemonstration complete.\n" + "="*40 + "\n")

    print("===== RailOpt AI Project Pipeline Finished =====\n")

# Execute the main function
main()

import os
import pandas as pd
from stable_baselines3 import PPO
from stable_baselines3.common.evaluation import evaluate_policy
# from digital_twin_env import DigitalTwinEnv # Import removed, class defined below

# --- Configuration ---
MODEL_PATH = "models/railopt_ai_agent.zip"
DATA_PATH = "data/"
N_EVAL_EPISODES = 10 # Number of episodes for full evaluation

# 3. Digital Twin Environment (digital_twin_env.py) - Class Definition (Included for independent execution)
import gymnasium as gym
from gymnasium import spaces
import numpy as np
import pandas as pd
import random

class DigitalTwinEnv(gym.Env):
    """A Gymnasium environment for the railway Digital Twin."""
    def __init__(self, timetable_df, tracks_df):
        super(DigitalTwinEnv, self).__init__()

        self.timetable = timetable_df
        self.tracks = tracks_df.set_index('track_id').to_dict('index')
        self.train_ids = self.timetable['train_no'].unique()
        self.num_trains = len(self.train_ids)
        self.num_tracks = len(self.tracks)

        # Action: For each train, decide to HOLD (0) or PROCEED (1)
        self.action_space = spaces.MultiBinary(self.num_trains)

        # Observation: [train_pos, train_delay] for each train
        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(self.num_trains * 2,), dtype=np.float32)

        self.reset()

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self.time = 0
        self.train_states = {}

        for train_id in self.train_ids:
            # Introduce a random initial delay for some trains to create disruptions
            initial_delay = random.randint(0, 15) if random.random() < 0.3 else 0
            self.train_states[train_id] = {
                'position_km': 0,
                'current_track_idx': 0,
                'delay_mins': initial_delay,
                'status': 'RUNNING',
                'route': self.timetable[self.timetable['train_no'] == train_id].to_dict('records')
            }
        return self._get_obs(), self._get_info()

    def step(self, action):
        reward = 0

        # Simple conflict detection: check single-line track usage
        occupied_single_tracks = set()

        for i, train_id in enumerate(self.train_ids):
            state = self.train_states[train_id]
            if state['status'] != 'RUNNING':
                continue

            # If action is HOLD, the train doesn't move
            if action[i] == 0:
                state['delay_mins'] += 1
                continue

            route_step = state['route'][state['current_track_idx']]
            track_id = route_step['track_id']
            track_info = self.tracks[track_id]

            # Conflict check for single line
            if track_info['is_single_line']:
                if track_id in occupied_single_tracks:
                    state['delay_mins'] += 1 # Cannot proceed, another train is on the single line
                    reward -= 10 # Penalty for conflict
                    continue
                else:
                    occupied_single_tracks.add(track_id)

            # Move the train
            avg_speed = track_info['max_speed_kmh'] * 0.75
            dist_per_min = avg_speed / 60
            state['position_km'] += dist_per_min

            # Check if arrived at next station
            if state['position_km'] >= track_info['length_km']:
                state['current_track_idx'] += 1
                state['position_km'] = 0
                if state['current_track_idx'] >= len(state['route']):
                    state['status'] = 'ARRIVED'
                    reward += 100 # Reward for finishing
                else:
                    # Check for delay at station
                    current_arrival_time = self.time
                    scheduled_arrival = state['route'][state['current_track_idx']-1]['scheduled_arrival']
                    state['delay_mins'] = max(0, current_arrival_time - scheduled_arrival)
                    reward -= state['delay_mins'] # Penalty proportional to delay

        self.time += 1 # Each step is one minute

        terminated = all(s['status'] == 'ARRIVED' for s in self.train_states.values())
        return self._get_obs(), reward, terminated, False, self._get_info()

    def _get_obs(self):
        obs = np.zeros(self.observation_space.shape, dtype=np.float32)
        for i, train_id in enumerate(self.train_ids):
            state = self.train_states[train_id]
            obs[i*2] = state['position_km']
            obs[i*2 + 1] = state['delay_mins']
        return obs

    def _get_info(self):
        return {id: s['delay_mins'] for id, s in self.train_states.items()}

    def render(self):
        print(f"\n--- Time: {self.time} minutes ---")
        for train_id, state in self.train_states.items():
            if state['status'] == 'RUNNING':
                route_step = state['route'][state['current_track_idx']]
                track_id = route_step['track_id']
                track_len = self.tracks[track_id]['length_km']
                progress = int((state['position_km'] / track_len) * 20)
                track_viz = f"[{'='*progress}>{'-'*(20-progress)}]"
                print(f"  Train {train_id}: {route_step['station_from']} {track_viz} {route_step['station_to']} | Delay: {int(state['delay_mins'])} min")
            else:
                print(f"  Train {train_id}: {state['status']}")


def load_environment():
    """Loads and returns the Digital Twin environment."""
    if not all(os.path.exists(os.path.join(DATA_PATH, f)) for f in ['generated_timetable.csv', 'tracks.csv']):
        print("Error: Data files not found. Please run main.py first to generate data.")
        exit()

    timetable_df = pd.read_csv(os.path.join(DATA_PATH, 'generated_timetable.csv'))
    tracks_df = pd.read_csv(os.path.join(DATA_PATH, 'tracks.csv'))

    env = DigitalTwinEnv(timetable_df, tracks_df)
    return env

def run_single_simulation(model, env):
    """Runs one full episode with the trained agent and renders the output."""
    print("\n--- Running a single, complete simulation with the trained agent ---")
    obs, info = env.reset()
    env.render()
    total_reward = 0

    for step in range(500): # Max steps to prevent infinite loops
        action, _states = model.predict(obs, deterministic=True)
        obs, reward, terminated, truncated, info = env.step(action)
        total_reward += reward
        env.render()
        if terminated:
            print("\n--- Simulation Finished: All trains arrived! ---")
            break

    print(f"\nFinal Delays: {info}")
    print(f"Total Reward for this episode: {total_reward:.2f}")

def evaluate_model_performance(model, env):
    """Uses Stable Baselines3's helper to evaluate the model over multiple episodes."""
    print(f"\n--- Evaluating model performance over {N_EVAL_EPISODES} episodes ---")
    print("This will run multiple simulations and calculate the average performance.")

    mean_reward, std_reward = evaluate_policy(model, env, n_eval_EPISodes=N_EVAL_EPISODES)

    print("\n--- Evaluation Complete ---")
    print(f"Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}")
    print("A higher and more stable reward indicates a better, more consistent agent.")

def interactive_mode(model, env):
    """Allows the user to step through the simulation and override AI actions."""
    print("\n--- Entering Interactive Mode ---")
    print("At each step, the AI's action will be shown.")
    print("Press ENTER to apply the AI's action, or type your own.")
    print("Your action should be a sequence of 0s and 1s separated by commas.")
    print(f"Example for {env.num_trains} trains: 1,0,1,1 (Proceed, Hold, Proceed, Proceed)")

    obs, info = env.reset()
    env.render()

    for step in range(500):
        ai_action, _ = model.predict(obs, deterministic=True)

        # Make AI action human-readable
        action_str = []
        for i, train_id in enumerate(env.train_ids):
            decision = "PROCEED" if ai_action[i] == 1 else "HOLD"
            action_str.append(f"{decision} {train_id}")

        print("\n-------------------------------------------")
        print(f"AI recommends: {', '.join(action_str)}")

        user_input = input("Your action (or press Enter for AI): ")

        chosen_action = ai_action
        if user_input.strip():
            try:
                # Parse user input
                parts = [int(p.strip()) for p in user_input.split(',')]
                if len(parts) == env.num_trains and all(p in [0, 1] for p in parts):
                    chosen_action = parts
                    print("--> Overriding with your action.")
                else:
                    print("--> Invalid format. Using AI action instead.")
            except ValueError:
                print("--> Invalid input. Using AI action instead.")

        obs, reward, terminated, truncated, info = env.step(chosen_action)
        env.render()

        if terminated:
            print("\n--- Simulation Finished: All trains arrived! ---")
            break

def main():
    """Main function to load the model and provide testing options."""
    if not os.path.exists(MODEL_PATH):
        print(f"Error: Model file not found at '{MODEL_PATH}'")
        print("Please run main.py first to train and save the agent.")
        return

    print("--- RailOpt AI Agent Testing Suite ---")
    print(f"Loading trained model from {MODEL_PATH}...")
    model = PPO.load(MODEL_PATH)
    env = load_environment()

    while True:
        print("\nPlease choose a testing mode:")
        print("  1: Run a single, fast simulation")
        print("  2: Get a full performance evaluation (takes longer)")
        print("  3: Enter interactive mode (step-by-step control)")
        print("  q: Quit")

        choice = input("Enter your choice: ")

        if choice == '1':
            run_single_simulation(model, env)
        elif choice == '2':
            evaluate_model_performance(model, env)
        elif choice == '3':
            interactive_mode(model, env)
        elif choice.lower() == 'q':
            print("Exiting testing suite.")
            break
        else:
            print("Invalid choice. Please try again.")

if __name__ == '__main__':
    main()



""" **visualization**

"""

import matplotlib.pyplot as plt
import networkx as nx

def visualize_railway_state(env):
    """
    Generates a graphical representation of the railway environment state.

    Args:
        env: An instance of the DigitalTwinEnv.
    """
    plt.clf() # Clear the previous plot
    plt.figure(figsize=(15, 5)) # Adjust figure size for better visualization of a line

    G = nx.Graph()
    station_positions = {}
    # Create nodes (stations) and define their positions for a linear layout
    # We'll just use an increasing index as the x-coordinate for simplicity
    for i, station in env.stations.iterrows():
        station_positions[station['station_id']] = (i, 0) # Linear layout along x-axis
        G.add_node(station['station_id'], name=station['station_name'])

    # Add edges (tracks) and differentiate single lines
    edge_colors = []
    edge_styles = []
    for _, track in env.tracks_df.iterrows():
        G.add_edge(track['start_station'], track['end_station'], track_id=track['track_id'])
        if track['is_single_line']:
            edge_colors.append('red')
            edge_styles.append('dashed')
        else:
            edge_colors.append('blue')
            edge_styles.append('solid')

    # Draw the network
    nx.draw(G, pos=station_positions, with_labels=True, node_size=700, node_color='lightgray', font_size=10,
            edge_color=edge_colors, style=edge_styles, width=2)

    # Draw trains
    train_markers = {}
    for train_id, state in env.train_states.items():
        if state['status'] == 'RUNNING':
            current_track_idx = state['current_track_idx']
            if current_track_idx < len(state['route']):
                route_step = state['route'][current_track_idx]
                start_station_id = route_step['station_from']
                end_station_id = route_step['station_to']
                track_id = route_step['track_id']
                track_info = env.tracks[track_id]

                # Calculate position along the edge (0 to 1)
                position_on_track = state['position_km'] / track_info['length_km']

                # Get station positions
                start_pos = station_positions[start_station_id]
                end_pos = station_positions[end_station_id]

                # Interpolate train position
                train_x = start_pos[0] + (end_pos[0] - start_pos[0]) * position_on_track
                train_y = start_pos[1] + (end_pos[1] - start_pos[1]) * position_on_track

                # Draw train marker
                plt.plot(train_x, train_y, 'o', color='green', markersize=10, label=f'{train_id} ({int(state["delay_mins"])} min)')

                # Add text label for train number and delay
                plt.text(train_x, train_y + 0.1, f'{train_id}\n({int(state["delay_mins"])})', fontsize=8, ha='center')

    plt.title(f"Railway Digital Twin Simulation - Time: {env.time} minutes")
    plt.axis('off') # Hide axes
    plt.tight_layout()
    plt.draw()
    plt.pause(0.01) # Pause to allow the plot to update

# Enable interactive plotting
plt.ion()

import matplotlib.pyplot as plt
import networkx as nx

def visualize_railway_state(env):
    """
    Generates a graphical representation of the railway environment state.

    Args:
        env: An instance of the DigitalTwinEnv.
    """
    plt.clf() # Clear the previous plot
    plt.figure(figsize=(15, 5)) # Adjust figure size for better visualization of a line

    G = nx.Graph()
    station_positions = {}
    # Create nodes (stations) and define their positions for a linear layout
    # We'll just use an increasing index as the x-coordinate for simplicity
    for i, station in env.stations.iterrows():
        station_positions[station['station_id']] = (i, 0) # Linear layout along x-axis
        G.add_node(station['station_id'], name=station['station_name'])

    # Add edges (tracks) and differentiate single lines
    edge_colors = []
    edge_styles = []
    for _, track in env.tracks_df.iterrows():
        G.add_edge(track['start_station'], track['end_station'], track_id=track['track_id'])
        if track['is_single_line']:
            edge_colors.append('red')
            edge_styles.append('dashed')
        else:
            edge_colors.append('blue')
            edge_styles.append('solid')

    # Draw the network
    nx.draw(G, pos=station_positions, with_labels=True, node_size=700, node_color='lightgray', font_size=10,
            edge_color=edge_colors, style=edge_styles, width=2)

    # Draw trains
    train_markers = {}
    for train_id, state in env.train_states.items():
        if state['status'] == 'RUNNING':
            current_track_idx = state['current_track_idx']
            if current_track_idx < len(state['route']):
                route_step = state['route'][current_track_idx]
                start_station_id = route_step['station_from']
                end_station_id = route_step['station_to']
                track_id = route_step['track_id']
                track_info = env.tracks[track_id]

                # Calculate position along the edge (0 to 1)
                position_on_track = state['position_km'] / track_info['length_km']

                # Get station positions
                start_pos = station_positions[start_station_id]
                end_pos = station_positions[end_station_id]

                # Interpolate train position
                train_x = start_pos[0] + (end_pos[0] - start_pos[0]) * position_on_track
                train_y = start_pos[1] + (end_pos[1] - start_pos[1]) * position_on_track

                # Draw train marker
                plt.plot(train_x, train_y, 'o', color='green', markersize=10, label=f'{train_id} ({int(state["delay_mins"])} min)')

                # Add text label for train number and delay
                plt.text(train_x, train_y + 0.1, f'{train_id}\n({int(state["delay_mins"])} min)', fontsize=8, ha='center')

    plt.title(f"Railway Digital Twin Simulation - Time: {env.time} minutes")
    plt.axis('off') # Hide axes
    plt.tight_layout()
    plt.draw()
    plt.pause(0.01) # Pause to allow the plot to update

# Enable interactive plotting
plt.ion()

# 3. Digital Twin Environment (digital_twin_env.py) - Class Definition (Included for independent execution)
import gymnasium as gym
from gymnasium import spaces
import numpy as np
import pandas as pd
import random
# visualization imports
import matplotlib.pyplot as plt
import networkx as nx

class DigitalTwinEnv(gym.Env):
    """A Gymnasium environment for the railway Digital Twin."""
    def __init__(self, timetable_df, tracks_df):
        super(DigitalTwinEnv, self).__init__()

        self.timetable = timetable_df
        self.tracks_df = tracks_df # Keep original tracks_df for visualization
        self.tracks = tracks_df.set_index('track_id').to_dict('index')
        self.stations = pd.read_csv('data/stations.csv') # Load stations for visualization
        self.train_ids = self.timetable['train_no'].unique()
        self.num_trains = len(self.train_ids)
        self.num_tracks = len(self.tracks)

        # Action: For each train, decide to HOLD (0) or PROCEED (1)
        self.action_space = spaces.MultiBinary(self.num_trains)

        # Observation: [train_pos, train_delay] for each train
        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(self.num_trains * 2,), dtype=np.float32)

        self.reset()

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self.time = 0
        self.train_states = {}

        for train_id in self.train_ids:
            # Introduce a random initial delay for some trains to create disruptions
            initial_delay = random.randint(0, 15) if random.random() < 0.3 else 0
            self.train_states[train_id] = {
                'position_km': 0,
                'current_track_idx': 0,
                'delay_mins': initial_delay,
                'status': 'RUNNING',
                'route': self.timetable[self.timetable['train_no'] == train_id].to_dict('records')
            }
        return self._get_obs(), self._get_info()

    def step(self, action):
        reward = 0

        # Simple conflict detection: check single-line track usage
        occupied_single_tracks = set()

        for i, train_id in enumerate(self.train_ids):
            state = self.train_states[train_id]
            if state['status'] != 'RUNNING':
                continue

            # If action is HOLD, the train doesn't move
            if action[i] == 0:
                state['delay_mins'] += 1
                continue

            route_step = state['route'][state['current_track_idx']]
            track_id = route_step['track_id']
            track_info = self.tracks[track_id]

            # Conflict check for single line
            if track_info['is_single_line']:
                if track_id in occupied_single_tracks:
                    state['delay_mins'] += 1 # Cannot proceed, another train is on the single line
                    reward -= 10 # Penalty for conflict
                    continue
                else:
                    occupied_single_tracks.add(track_id)

            # Move the train
            avg_speed = track_info['max_speed_kmh'] * 0.75
            dist_per_min = avg_speed / 60
            state['position_km'] += dist_per_min

            # Check if arrived at next station
            if state['position_km'] >= track_info['length_km']:
                state['current_track_idx'] += 1
                state['position_km'] = 0
                if state['current_track_idx'] >= len(state['route']):
                    state['status'] = 'ARRIVED'
                    reward += 100 # Reward for finishing
                else:
                    # Check for delay at station
                    current_arrival_time = self.time
                    scheduled_arrival = state['route'][state['current_track_idx']-1]['scheduled_arrival']
                    state['delay_mins'] = max(0, current_arrival_time - scheduled_arrival)
                    reward -= state['delay_mins'] # Penalty proportional to delay

        self.time += 1 # Each step is one minute

        terminated = all(s['status'] == 'ARRIVED' for s in self.train_states.values())
        return self._get_obs(), reward, terminated, False, self._get_info()

    def _get_obs(self):
        obs = np.zeros(self.observation_space.shape, dtype=np.float32)
        for i, train_id in enumerate(self.train_ids):
            state = self.train_states[train_id]
            obs[i*2] = state['position_km']
            obs[i*2 + 1] = state['delay_mins']
        return obs

    def _get_info(self):
        return {id: s['delay_mins'] for id, s in self.train_states.items()}

    def render(self):
        # Call the graphical visualization function
        visualize_railway_state(self)

# Define the visualization function (copied from previous step for standalone execution)
def visualize_railway_state(env):
    """
    Generates a graphical representation of the railway environment state.

    Args:
        env: An instance of the DigitalTwinEnv.
    """
    plt.clf() # Clear the previous plot
    plt.figure(figsize=(15, 5)) # Adjust figure size for better visualization of a line

    G = nx.Graph()
    station_positions = {}
    # Create nodes (stations) and define their positions for a linear layout
    # We'll just use an increasing index as the x-coordinate for simplicity
    for i, station in env.stations.iterrows():
        station_positions[station['station_id']] = (i, 0) # Linear layout along x-axis
        G.add_node(station['station_id'], name=station['station_name'])

    # Add edges (tracks) and differentiate single lines
    edge_colors = []
    edge_styles = []
    for _, track in env.tracks_df.iterrows():
        G.add_edge(track['start_station'], track['end_station'], track_id=track['track_id'])
        if track['is_single_line']:
            edge_colors.append('red')
            edge_styles.append('dashed')
        else:
            edge_colors.append('blue')
            edge_styles.append('solid')

    # Draw the network
    nx.draw(G, pos=station_positions, with_labels=True, node_size=700, node_color='lightgray', font_size=10,
            edge_color=edge_colors, style=edge_styles, width=2)

    # Draw trains
    train_markers = {}
    for train_id, state in env.train_states.items():
        if state['status'] == 'RUNNING':
            current_track_idx = state['current_track_idx']
            if current_track_idx < len(state['route']):
                route_step = state['route'][current_track_idx]
                start_station_id = route_step['station_from']
                end_station_id = route_step['station_to']
                track_id = route_step['track_id']
                track_info = env.tracks[track_id]

                # Calculate position along the edge (0 to 1)
                position_on_track = state['position_km'] / track_info['length_km']

                # Get station positions
                start_pos = station_positions[start_station_id]
                end_pos = station_positions[end_station_id]

                # Interpolate train position
                train_x = start_pos[0] + (end_pos[0] - start_pos[0]) * position_on_track
                train_y = start_pos[1] + (end_pos[1] - start_pos[1]) * position_on_track

                # Draw train marker
                plt.plot(train_x, train_y, 'o', color='green', markersize=10, label=f'{train_id} ({int(state["delay_mins"])} min)')

                # Add text label for train number and delay
                plt.text(train_x, train_y + 0.1, f'{train_id}\n({int(state["delay_mins"])} min)', fontsize=8, ha='center')

    plt.title(f"Railway Digital Twin Simulation - Time: {env.time} minutes")
    plt.axis('off') # Hide axes
    plt.tight_layout()
    plt.draw()
    plt.pause(0.01) # Pause to allow the plot to update

# Enable interactive plotting
plt.ion()

# The rest of the main function and other imports/definitions remain the same
from stable_baselines3 import PPO
from stable_baselines3.common.evaluation import evaluate_policy
import os

# --- Configuration ---
MODEL_PATH = "models/railopt_ai_agent.zip"
DATA_PATH = "data/"
N_EVAL_EPISODES = 10 # Number of episodes for full evaluation

def generate_data():
    """Generates and saves synthetic railway data as CSV files."""
    print("Creating synthetic data for a railway corridor...")

    # Create a directory for data if it doesn't exist
    if not os.path.exists('data'):
        os.makedirs('data')

    # 1. Stations Data
    stations_data = {
        'station_id': ['MAS', 'AJJ', 'KPD', 'JTJ', 'SBC'],
        'station_name': ['Chennai Central', 'Arakkonam Jn', 'Katpadi Jn', 'Jolarpettai Jn', 'Bengaluru City'],
        'type': ['Terminal', 'Junction', 'Junction', 'Junction', 'Terminal']
    }
    stations_df = pd.DataFrame(stations_data)
    stations_df.to_csv('data/stations.csv', index=False)
    print("  - data/stations.csv created.")

    # 2. Tracks Data (Connecting the stations)
    tracks_data = {
        'track_id': ['MAS-AJJ', 'AJJ-KPD', 'KPD-JTJ', 'JTJ-SBC'],
        'start_station': ['MAS', 'AJJ', 'KPD', 'JTJ'],
        'end_station': ['AJJ', 'KPD', 'JTJ', 'SBC'],
        'length_km': [69, 64, 85, 140],
        'max_speed_kmh': [110, 120, 110, 100],
        'is_single_line': [False, False, True, False] # KPD-JTJ is a single-line bottleneck
    }
    tracks_df = pd.DataFrame(tracks_data)
    tracks_df.to_csv('data/tracks.csv', index=False)
    print("  - data/tracks.csv created.")

    # 3. Initial Train Service Requests
    schedule_requests_data = {
        'train_no': [12607, 12007, 22625, '06021-F'],
        'train_name': ['Lalbagh Express', 'Shatabdi Express', 'Double Decker Exp', 'Goods Freight'],
        'start_station': ['MAS', 'MAS', 'MAS', 'MAS'],
        'end_station': ['SBC', 'SBC', 'SBC', 'SBC'],
        'priority': [2, 1, 2, 3] # 1 is highest priority
    }
    schedule_requests_df = pd.DataFrame(schedule_requests_data)
    schedule_requests_df.to_csv('data/schedule_requests.csv', index=False)
    print("  - data/schedule_requests.csv created.")


import networkx as nx # Imported again because the DigitalTwinEnv class definition is included here

def create_schedule():
    """Reads network data and train requests to generate a full timetable."""
    print("Running Strategic Scheduler to generate master timetable...")

    stations_df = pd.read_csv('data/stations.csv')
    tracks_df = pd.read_csv('data/tracks.csv')
    requests_df = pd.read_csv('data/schedule_requests.csv')

    # Create a graph representation of the railway network
    G = nx.Graph()
    for _, station in stations_df.iterrows():
        G.add_node(station['station_id'], name=station['station_name'])
    for _, track in tracks_df.iterrows():
        # Calculate travel time in minutes as weight
        travel_time = (track['length_km'] / (track['max_speed_kmh'] * 0.75)) * 60 # Assume avg speed is 75% of max
        G.add_edge(track['start_station'], track['end_station'], weight=travel_time, track_id=track['track_id'])

    timetable = []
    current_time = 0 # Simple time staggering, starts at minute 0

    # Sort requests by priority to schedule important trains first
    requests_df = requests_df.sort_values(by='priority')

    for _, train in requests_df.iterrows():
        path = nx.shortest_path(G, source=train['start_station'], target=train['end_station'], weight='weight')

        departure_time = current_time
        arrival_time = departure_time

        for i in range(len(path) - 1):
            start_node = path[i]
            end_node = path[i+1]
            edge_data = G.get_edge_data(start_node, end_node)
            travel_time = edge_data['weight']

            timetable.append({
                'train_no': train['train_no'],
                'train_name': train['train_name'],
                'sequence': i + 1,
                'station_from': start_node,
                'station_to': end_node,
                'scheduled_departure': arrival_time,
                'scheduled_arrival': arrival_time + travel_time,
                'track_id': edge_data['track_id']
            })
            arrival_time += travel_time + 5 # Add 5 min halt time at each station

        # Stagger the next train's departure
        current_time += 15

    timetable_df = pd.DataFrame(timetable)
    timetable_df.to_csv('data/generated_timetable.csv', index=False)
    print("  - Master timetable created: data/generated_timetable.csv")


def train_agent():
    """Initializes the environment and trains the PPO agent."""
    print("Loading data for the Digital Twin Environment...")
    timetable_df = pd.read_csv('data/generated_timetable.csv')
    tracks_df = pd.read_csv('data/tracks.csv')

    # Create the Digital Twin environment
    # DigitalTwinEnv is defined in this cell
    env = DigitalTwinEnv(timetable_df, tracks_df)

    # Instantiate the PPO model
    model = PPO("MlpPolicy", env, verbose=0)

    # Train the agent
    print("Training the RL agent... (This may take a few minutes)")
    # Note: 10,000 timesteps is for a quick demonstration. A real model would need millions.
    model.learn(total_timesteps=10000)
    print("  - Training complete.")

    # Save the trained model
    if not os.path.exists('models'):
        os.makedirs('models')
    model.save("models/railopt_ai_agent")
    print("  - Trained model saved to models/railopt_ai_agent.zip")

    return model, env

def run_simulation_with_agent(model, env):
    """Runs a single simulation episode using the trained agent and renders it."""
    print("\n--- Running simulation with the TRAINED agent ---")
    obs, info = env.reset()
    env.render()

    for _ in range(200): # Max steps per episode
        action, _states = model.predict(obs, deterministic=True)
        obs, reward, terminated, truncated, info = env.step(action)
        env.render()
        if terminated:
            print("--- All trains arrived! ---")
            break

def load_environment():
    """Loads and returns the Digital Twin environment."""
    if not all(os.path.exists(os.path.join(DATA_PATH, f)) for f in ['generated_timetable.csv', 'tracks.csv', 'stations.csv']):
        print("Error: Data files not found. Please run main.py first to generate data.")
        exit()

    timetable_df = pd.read_csv(os.path.join(DATA_PATH, 'generated_timetable.csv'))
    tracks_df = pd.read_csv(os.path.join(DATA_PATH, 'tracks.csv'))

    env = DigitalTwinEnv(timetable_df, tracks_df)
    return env

def run_single_simulation(model, env):
    """Runs one full episode with the trained agent and renders the output."""
    print("\n--- Running a single, complete simulation with the trained agent ---")
    obs, info = env.reset()
    env.render()
    total_reward = 0

    for step in range(500): # Max steps to prevent infinite loops
        action, _states = model.predict(obs, deterministic=True)
        obs, reward, terminated, truncated, info = env.step(action)
        total_reward += reward
        env.render()
        if terminated:
            print("\n--- Simulation Finished: All trains arrived! ---")
            break

    print(f"\nFinal Delays: {info}")
    print(f"Total Reward for this episode: {total_reward:.2f}")

def evaluate_model_performance(model, env):
    """Uses Stable Baselines3's helper to evaluate the model over multiple episodes."""
    print(f"\n--- Evaluating model performance over {N_EVAL_EPISODES} episodes ---")
    print("This will run multiple simulations and calculate the average performance.")

    mean_reward, std_reward = evaluate_policy(model, env, n_eval_EPISodes=N_EVAL_EPISODES)

    print("\n--- Evaluation Complete ---")
    print(f"Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}")
    print("A higher and more stable reward indicates a better, more consistent agent.")

def interactive_mode(model, env):
    """Allows the user to step through the simulation and override AI actions."""
    print("\n--- Entering Interactive Mode ---")
    print("At each step, the AI's action will be shown.")
    print("Press ENTER to apply the AI's action, or type your own.")
    print("Your action should be a sequence of 0s and 1s separated by commas.")
    print(f"Example for {env.num_trains} trains: 1,0,1,1 (Proceed, Hold, Proceed, Proceed)")

    obs, info = env.reset()
    env.render()

    for step in range(500):
        ai_action, _ = model.predict(obs, deterministic=True)

        # Make AI action human-readable
        action_str = []
        for i, train_id in enumerate(env.train_ids):
            decision = "PROCEED" if ai_action[i] == 1 else "HOLD"
            action_str.append(f"{decision} {train_id}")

        print("\n-------------------------------------------")
        print(f"AI recommends: {', '.join(action_str)}")

        user_input = input("Your action (or press Enter for AI): ")

        chosen_action = ai_action
        if user_input.strip():
            try:
                # Parse user input
                parts = [int(p.strip()) for p in user_input.split(',')]
                if len(parts) == env.num_trains and all(p in [0, 1] for p in parts):
                    chosen_action = parts
                    print("--> Overriding with your action.")
                else:
                    print("--> Invalid format. Using AI action instead.")
            except ValueError:
                print("--> Invalid input. Using AI action instead.")

        obs, reward, terminated, truncated, info = env.step(chosen_action)
        env.render()

        if terminated:
            print("\n--- Simulation Finished: All trains arrived! ---")
            break

def main():
    """Main function to load the model and provide testing options."""
    if not os.path.exists(MODEL_PATH):
        print(f"Error: Model file not found at '{MODEL_PATH}'")
        print("Please run main.py first to train and save the agent.")
        return

    print("--- RailOpt AI Agent Testing Suite ---")
    print(f"Loading trained model from {MODEL_PATH}...")
    model = PPO.load(MODEL_PATH)
    env = load_environment()

    while True:
        print("\nPlease choose a testing mode:")
        print("  1: Run a single, fast simulation")
        print("  2: Get a full performance evaluation (takes longer)")
        print("  3: Enter interactive mode (step-by-step control)")
        print("  q: Quit")

        choice = input("Enter your choice: ")

        if choice == '1':
            run_single_simulation(model, env)
        elif choice == '2':
            evaluate_model_performance(model, env)
        elif choice == '3':
            interactive_mode(model, env)
        elif choice.lower() == 'q':
            print("Exiting testing suite.")
            break
        else:
            print("Invalid choice. Please try again.")

if __name__ == '__main__':
    main()

# Demonstrate Graphical Visualization
print("--- Running simulation with Graphical Visualization ---")

# Load the environment
# Assuming load_environment and DigitalTwinEnv are defined in previous cells
env = load_environment()

# Run a simulation episode and visualize
obs, info = env.reset()
env.render() # Render initial state

for step in range(500): # Max steps to prevent infinite loops
    # For demonstration, we'll use a simple random action or a loaded model's prediction
    # action, _states = model.predict(obs, deterministic=True) # Uncomment and use 'model' if you have trained one
    action = env.action_space.sample() # Use random actions for basic visualization demo

    obs, reward, terminated, truncated, info = env.step(action)
    env.render() # Render the state after the step

    if terminated:
        print("\n--- Simulation Finished: All trains arrived! ---")
        break

print("\nGraphical visualization demonstration complete.")